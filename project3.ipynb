{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Project 3 - Classification\n",
    "Welcome to the third project of Data 8!  You will build a classifier that guesses whether a song is hip-hop or country, using only the numbers of times words appear in the song's lyrics.  By the end of the project, you should know how to:\n",
    "\n",
    "1. Build a k-nearest-neighbors classifier.\n",
    "2. Test a classifier on data.\n",
    "\n",
    "### Logistics\n",
    "\n",
    "\n",
    "**Deadline.** This project is due at 11:59pm on Thursday 4/27. You can earn an early submission bonus point by submitting your completed project by Wednesday 4/26. Late submissions will be accepted until Tuesday 5/2, but a 10% late penalty will be applied for each day late. It's **much** better to be early than late, so start working now.\n",
    "\n",
    "**Checkpoint.** For full credit, you must also **complete Part 1 of the project (out of 4) and submit them by 11:59pm on Friday 4/21**. You will have some lab time to work on these questions, but we recommend that you start the project before lab and leave time to finish the checkpoint afterward.\n",
    "\n",
    "**Partners.** You may work with one other partner. It's best to work with someone in your lab. Only one of you is required to submit the project. On [okpy.org](http://okpy.org), the person who submits should also designate their partner so that both of you receive credit.\n",
    "\n",
    "**Rules.** Don't share your code with anybody but your partner. You are welcome to discuss questions with other students, but don't share the answers. The experience of solving the problems in this project will prepare you for exams (and life). If someone asks you for the answer, resist! Instead, you can demonstrate how you would solve a similar problem.\n",
    "\n",
    "**Support.** You are not alone! Come to office hours, post on Piazza, and talk to your classmates. If you want to ask about the details of your solution to a problem, make a private Piazza post and the staff will respond. If you're ever feeling overwhelmed or don't know how to make progress, email your TA or tutor for help. You can find contact information for the staff on the [course website](http://data8.org/sp17/staff.html).\n",
    "\n",
    "**Tests.** Passing the tests for a question **does not** mean that you answered the question correctly. Tests usually only check that your table has the correct column labels. However, more tests will be applied to verify the correctness of your submission in order to assign your final score, so be careful and check your work!\n",
    "\n",
    "**Advice.** Develop your answers incrementally. To perform a complicated table manipulation, break it up into steps, perform each step on a different line, give a new name to each result, and check that each intermediate result is what you expect. You can add any additional names or functions you want to the provided cells. \n",
    "\n",
    "To get started, load `datascience`, `numpy`, `plots`, and `ok`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datascience in /Users/kevinko/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: coverage==3.7.1 in /Users/kevinko/anaconda3/lib/python3.6/site-packages (from datascience)\n",
      "Requirement already satisfied: setuptools in /Users/kevinko/anaconda3/lib/python3.6/site-packages/setuptools-27.2.0-py3.6.egg (from datascience)\n",
      "Requirement already satisfied: pytest in /Users/kevinko/anaconda3/lib/python3.6/site-packages (from datascience)\n",
      "Requirement already satisfied: folium==0.1.5 in /Users/kevinko/anaconda3/lib/python3.6/site-packages (from datascience)\n",
      "Requirement already satisfied: sphinx in /Users/kevinko/anaconda3/lib/python3.6/site-packages/Sphinx-1.5.1-py3.6.egg (from datascience)\n",
      "Requirement already satisfied: coveralls==0.5 in /Users/kevinko/anaconda3/lib/python3.6/site-packages (from datascience)\n",
      "Requirement already satisfied: py>=1.4.29 in /Users/kevinko/anaconda3/lib/python3.6/site-packages (from pytest->datascience)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kevinko/anaconda3/lib/python3.6/site-packages (from sphinx->datascience)\n",
      "Requirement already satisfied: Jinja2>=2.3 in /Users/kevinko/anaconda3/lib/python3.6/site-packages (from sphinx->datascience)\n",
      "Requirement already satisfied: Pygments>=2.0 in /Users/kevinko/anaconda3/lib/python3.6/site-packages (from sphinx->datascience)\n",
      "Requirement already satisfied: docutils>=0.11 in /Users/kevinko/anaconda3/lib/python3.6/site-packages (from sphinx->datascience)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /Users/kevinko/anaconda3/lib/python3.6/site-packages (from sphinx->datascience)\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in /Users/kevinko/anaconda3/lib/python3.6/site-packages (from sphinx->datascience)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /Users/kevinko/anaconda3/lib/python3.6/site-packages (from sphinx->datascience)\n",
      "Requirement already satisfied: imagesize in /Users/kevinko/anaconda3/lib/python3.6/site-packages (from sphinx->datascience)\n",
      "Requirement already satisfied: requests in /Users/kevinko/anaconda3/lib/python3.6/site-packages (from sphinx->datascience)\n",
      "Requirement already satisfied: docopt>=0.6.1 in /Users/kevinko/anaconda3/lib/python3.6/site-packages (from coveralls==0.5->datascience)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /Users/kevinko/anaconda3/lib/python3.6/site-packages (from coveralls==0.5->datascience)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/kevinko/anaconda3/lib/python3.6/site-packages (from Jinja2>=2.3->sphinx->datascience)\n",
      "Requirement already satisfied: pytz>=0a in /Users/kevinko/anaconda3/lib/python3.6/site-packages (from babel!=2.0,>=1.3->sphinx->datascience)\n",
      "Requirement already satisfied: client in /Users/kevinko/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already up-to-date: scikit-learn in /Users/kevinko/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already up-to-date: pip in /Users/kevinko/anaconda3/lib/python3.6/site-packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinko/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to set up the notebook, but please don't change it.\n",
    "!pip install datascience\n",
    "!pip install client\n",
    "import numpy as np\n",
    "import math\n",
    "from datascience import *\n",
    "\n",
    "# These lines set up the plotting functionality and formatting.\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg', warn=False)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# These lines load the tests.\n",
    "#from client.api.notebook import Notebook\n",
    "#ok = Notebook('project3.ok')\n",
    "#_ = ok.auth(inline=True)\n",
    "\n",
    "\n",
    "!pip install -U scikit-learn\n",
    "!pip install --upgrade pip\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1. The Dataset\n",
    "\n",
    "Our dataset is a table of songs, each with a name, an artist, and a genre.  We'll be trying to predict each song's genre.\n",
    "\n",
    "The only attributes we will use to predict the genre of a song are its lyrics. In particular, we have a list of just under 5,000 words that might occur in a song.  For each song, our dataset tells us the frequency with which each of these words occurs in that song. All words have been converted to lowercase.\n",
    "\n",
    "Run the cell below to read the `lyrics` table. **It may take up to a minute to load.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Title</th> <th>Artist</th> <th>Genre</th> <th>i</th> <th>the</th> <th>you</th> <th>like</th> <th>love</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>In Your Eyes</td> <td>Alison Krauss</td> <td>Country</td> <td>0.107143</td> <td>0   </td> <td>0.0297619</td> <td>0.0119048</td> <td>0.0595238</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Title        | Artist        | Genre   | i        | the  | you       | like      | love\n",
       "In Your Eyes | Alison Krauss | Country | 0.107143 | 0    | 0.0297619 | 0.0119048 | 0.0595238"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics = Table.read_table('lyrics.csv')\n",
    "lyrics.where(\"Title\", \"In Your Eyes\").select(0, 1, 2, 3, 4, 5, \"like\", \"love\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "That cell prints a few columns of the row for the country song [\"In Your Eyes\" by Alison Krauss](http://www.azlyrics.com/lyrics/alisonkrauss/inyoureyes.html).  The song contains 168 words. The word \"like\" appears twice:  $\\frac{2}{168} \\approx 0.0119$ of the words in the song. The word \"love\" appears 10 times: $\\frac{10}{168} \\approx 0.0595$ of the words. The word \"the\" doesn't appear at all.\n",
    "\n",
    "Our dataset doesn't contain all information about a song.  For example, it doesn't describe the order of words in the song, let alone the melody, instruments, or rhythm. Nonetheless, you may find that word frequencies alone are sufficient to build an accurate genre classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "All titles are unique. The `row_for_title` function provides fast access to the one row for each title. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ungraded and Optional: A Custom Classifier\n",
    "Try to create an even better classifier. You're not restricted to using only word proportions as features.  For example, given the data, you could compute various notions of vocabulary size or estimated song length.  If you're feeling very adventurous, you could also try other classification methods, like logistic regression.  If you think you built a classifier that works well, post on Piazza and let us know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "# Custom Classifier #\n",
    "#####################\n",
    "#SVC Best kernel = linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Kaggle Competition\n",
    "\n",
    "**Note:** This part is completely optional and will not contribute towards your grade in any way.\n",
    "\n",
    "We decided to *hold out* a set of 100 songs, for which we have provided the attributes but not the genres. You can use this set to evaluate how well you classifier performs on data for which you have never seen the correct genres. Optionally, you can submit your predictions on this dataset to Kaggle to compare your classifier to others (whoever else decides to participate).\n",
    "\n",
    "To participate, use your classifier to predict the genre of each row in the `holdout` table. Then, call ```create_competition_submission``` to generate a CSV file that you can submit to the competition!\n",
    "\n",
    "If you want to participate in the competition, you will have to create a Kaggle account. It's easiest for the staff to determine the winners of the competition if you use your `@berkeley.edu` email when doing so, but you can also contact your GSI if you decide to use another email address. Winners may receive honor and glory, but no material benefit.\n",
    "\n",
    "When you are ready to make a submission, go to https://inclass.kaggle.com/c/hip-hop-or-country for further instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entire Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "holdout = Table.read_table('holdout_attributes.csv').drop('Id')\n",
    "#holdout.select(0, 1, 2, 3, 4).show(5)\n",
    "\n",
    "contest = holdout.to_array()\n",
    "contest = [list(item) for item in contest]\n",
    "\n",
    "X = lyrics.drop(0, 1, 2).to_array()\n",
    "X = [list(item) for item in X]\n",
    "y = lyrics.column('Genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4817 4817\n"
     ]
    }
   ],
   "source": [
    "print(len(X[0]), len(contest[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X, y)\n",
    "y_pred = svm.predict(X)\n",
    "metrics.accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='sigmoid')\n",
    "svm.fit(X, y)\n",
    "y_pred = svm.predict(X)\n",
    "metrics.accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold()\n",
    "X = sel.fit_transform(X)\n",
    "contest = sel.transform(contest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(X[0]), len(contest[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=1000)\n",
    "\n",
    "# Maybe some original features where good, too?\n",
    "selection = SelectKBest(k=1000)\n",
    "\n",
    "# Build estimator from PCA and Univariate selection:\n",
    "\n",
    "combined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])\n",
    "\n",
    "# Use combined features to transform dataset:\n",
    "X_features = combined_features.fit(X, y).transform(X)\n",
    "\n",
    "svm = SVC(kernel=\"linear\")\n",
    "\n",
    "# Do grid search over k, n_components and C:\n",
    "\n",
    "pipeline = Pipeline([(\"features\", combined_features), (\"svm\", svm)])\n",
    "\n",
    "param_grid = dict(features__pca__n_components=[1, 2, 3],\n",
    "                  features__univ_select__k=[1, 2],\n",
    "                  svm__C=[0.1, 1, 10])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=10)\n",
    "grid_search.fit(X, y)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split-test Train + features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X_features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best features based on Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import samples_generator\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "clf.feature_importances_ \n",
    "model = SelectFromModel(clf, prefit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = model.transform(X)\n",
    "contest = model.transform(contest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(contest[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(38,))#solver='adam', learning_rate='adaptive', hidden_layer_sizes=(8,), alpha=1e-05, activation='tanh')#solver='', alpha=1e-5, hidden_layer_sizes=(34,), activation='logistic', learning_rate='constant')\n",
    "#{'solver': 'adam', 'learning_rate': 'adaptive', 'hidden_layer_sizes': 8, 'alpha': 1e-05, 'activation': 'tanh'}\n",
    "#{'solver': 'lbfgs', 'learning_rate': 'adaptive', 'hidden_layer_sizes': 32, 'alpha': 0.001, 'activation': 'tanh'}\n",
    "#{'learning_rate': 'constant', 'hidden_layer_sizes': 38, 'alpha': 0.001, 'activation': 'identity'}\n",
    "#{'solver': 'lbfgs', 'learning_rate': 'constant', 'hidden_layer_sizes': 34, 'alpha': 0.001, 'activation': 'logistic'}\n",
    "#{'learning_rate': 'constant', 'hidden_layer_sizes': 38, 'alpha': 0.001, 'activation': 'identity'}\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=3000, oob_score=True)#, min_samples_leaf=60, min_samples_split=2, bootstrap=False, criterion='entropy', max_features='sqrt') #min_samples_leaf=90, min_samples_split=9, max_depth=None)\n",
    "#{'bootstrap': True, 'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_leaf': 90, 'min_samples_split': 9, 'n_estimators': 1000}\n",
    "#{'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 60, 'min_samples_split': 9, 'n_estimators': 900}\n",
    "#{'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 6, 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 400}\n",
    "#{'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 10, 'min_samples_leaf': 2, 'min_samples_split': 7}\n",
    "#{'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 6}\n",
    "#{'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 9, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_dist = {\"n_estimators\": np.arange(100, 1100, 100),\n",
    "              #\"max_depth\": [3, None],\n",
    "              \"max_features\": [None, 'auto', 'sqrt', 0.3],\n",
    "              #\"min_samples_split\": sp_randint(2, 11),\n",
    "              #\"min_samples_leaf\": np.arange(50, 510, 10),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist)\n",
    "start = time()\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), 0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(random_search.best_score_)\n",
    "print(random_search.best_estimator_)\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(contest[0]), len(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(contest)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(gnb, X, y, cv=10, scoring='accuracy')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#contest = holdout.to_array()\n",
    "#contest = [list(item) for item in contest]\n",
    "#contest = model.transform(contest)\n",
    "gnb_pred = gnb.predict(contest)\n",
    "gnb_pred\n",
    "\n",
    "(79, 79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "gs = RandomizedSearchCV(clf, param_distributions={\n",
    "    'hidden_layer_sizes': np.arange(1, 50), \n",
    "    'alpha': [1e-5, 0.001, 0.1, 10, 1000],\n",
    "    'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "    'learning_rate' : ['constant', 'invscaling', 'adaptive'],\n",
    "    'activation' : ['identity', 'logistic', 'tanh', 'relu']})\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.best_estimator_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(holdout.num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_competition_submission(predictions, filename='my_submission.csv'):\n",
    "    \"\"\"\n",
    "    Create a submission CSV for the Kaggle competition.\n",
    "    \n",
    "    Inputs:\n",
    "      predictions - list or array of your predictions (Generated as in Question 3.3.1.)\n",
    "    \"\"\"\n",
    "    Table().with_columns('Id', np.arange(len(predictions)), 'Predictions', predictions).to_csv(filename)\n",
    "    print('Created', filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here's an example of how to generate a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "create_competition_submission(predictions, 'idkanymore.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
